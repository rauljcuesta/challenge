{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookings.csv  bookings.csv.bz2\tchallenge.ipynb  searches.csv  searches.csv.bz2\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000011\r\n"
     ]
    }
   ],
   "source": [
    "!cat bookings.csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20390198\r\n"
     ]
    }
   ],
   "source": [
    "!cat searches.csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-10-13^12:34:56^MPT^90e8ff571fc484463158eae496711466^SE^GOT^NBO^1^2^GOT^NBO^2013-12-05^^^NBO^GOT^2014-02-28^^^^^^^^^^^^^^^^^^^^^^^1ASIWS^0^0^0^d41d8cd98f00b204e9800998ecf8427e^0\r\n",
      "2013-10-13^10:03:58^FXP^9530f0a7e694bc9402885b4fa7e094bd^TR^DUS^ALA^1^4^DUS^IST^2013-12-16^EU^L^IST^ALA^2013-12-16^EU^L^ALA^IST^2013-12-24^EU^E^IST^DUS^2013-12-25^EU^E^^^^^^^^^^^1ASI^0^0^0^d41d8cd98f00b204e9800998ecf8427e^0\r\n",
      "2013-10-13^14:11:34^FXP^594fed8de13248512f6cf4cf9f6fc915^KW^KWI^LHR^1^2^KWI^LHR^2013-11-26^LK^F^LHR^KWI^2013-12-06^LK^F^^^^^^^^^^^^^^^^^^^^^1ASI^0^0^0^d41d8cd98f00b204e9800998ecf8427e^0\r\n",
      "2013-10-13^05:47:30^MPT^e175ff926640d0f543bb15f8b4a88ed0^US^MFE^MAD^0^1^MFE^MAD^2014-05-30^LK^^^^^^^^^^^^^^^^^^^^^^^^^^^1ASI^0^0^0^d41d8cd98f00b204e9800998ecf8427e^0\r\n",
      "2013-10-13^18:57:54^MTP^e41c9d833aa74600552f2ed688b67d81^AT^VIE^HA"
     ]
    }
   ],
   "source": [
    "!tail -5 searches.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-05-18 00:00:00^1A    ^LK      ^1a5585bef21f0bf8dc865a87843635f9^6ff8fd087f94799d7aed903683384775^3b339797f7eca14c24e8b7565da822c0^2013-05-14 00:00:00^13203^0^CMB     ^CMB     ^LK      ^MAA     ^MAA     ^IN      ^CMB     ^CMB     ^LK      ^MAA     ^MAA     ^IN      ^CMB     ^CMB     ^LK      ^CMBMAA  ^CMBMAA  ^INLK    ^1^MAACMB         ^FV^V        ^Y        ^2013-05-24 16:05:00^2013-05-24 17:38:39^-1^2013^5^NULL     \r\n",
      "2013-05-18 00:00:00^1A    ^LK      ^1a5585bef21f0bf8dc865a87843635f9^6ff8fd087f94799d7aed903683384775^3b339797f7eca14c24e8b7565da822c0^2013-05-14 00:00:00^6003^0^CMB     ^CMB     ^LK      ^MAA     ^MAA     ^IN      ^CMB     ^CMB     ^LK      ^MAA     ^MAA     ^IN      ^CMB     ^CMB     ^LK      ^CMBMAA  ^CMBMAA  ^INLK    ^1^MAACMB         ^FV^V        ^Y        ^2013-05-19 16:05:00^2013-05-19 17:38:39^1^2013^5^NULL     \r\n",
      "2013-05-28 00:00:00^1A    ^US      ^07e98d2fd3cd4b737266b99727f7faa8^e8741eaf2fa2f71f931475d18fa72096^2b22597bdad931843c3b1d5219836e07^2013-05-28 00:00:00^328^1865^AUS     ^AUS     ^US      ^RDU     ^RDU     ^US      ^RDU     ^RDU     ^US      ^AUS     ^AUS     ^US      ^RDU     ^RDU     ^US      ^AUSRDU  ^AUSRDU  ^USUS    ^0^AUSDFWRDU      ^KK^Q        ^Y        ^2013-07-12 08:35:00^2013-07-12 15:03:14^1^2013^5^SEAEX38AA\r\n",
      "2013-05-28 00:00:00^1A    ^FR      ^e2679367673d50f1ee085127d8a00eba^5f26f53ca29672815e0ee3bd93a2b0e4^4eb40315a7263131ae17712cd505b62a^2013-05-28 00:00:00^588^0^TLS     ^TLS     ^FR      ^ORY     ^PAR     ^FR      ^TLS     ^TLS     ^FR      ^TLS     ^TLS     ^FR      ^ORY     ^PAR     ^FR      ^ORYTLS  ^PARTLS  ^FRFR    ^0^TLSORY         ^KP^S        ^Y        ^2013-06-04 10:50:00^2013-06-04 12:18:20^1^2013^5^LYSSR210Z\r\n",
      "2013-05-28 00:00:00^1A    ^FR      ^e2679367673d50f1ee085127d8a00eba^5f26f53ca29672815e0ee3bd93a2b0e4^4eb40315a7263131ae17712cd505b62a^2013-05-28 00:00:00^588^0^TLS     ^TLS     ^FR      ^ORY     ^PAR     ^FR      ^TLS     ^TLS     ^FR      ^ORY     ^PAR     ^FR      ^TLS     ^TLS     ^FR      ^ORYTLS  ^PARTLS  ^FRFR    ^0^ORYTLS         ^KP^S        ^Y        ^2013-06-04 19:10:00^2013-06-04 20:38:20^1^2013^5^LYSSR210Z\r\n"
     ]
    }
   ],
   "source": [
    "!tail -5 bookings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('bookings.csv', index_col=0)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('searches.csv', index_col=0)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv('bookings.csv.bz2', compression='bz2', header=0, sep='^')\n",
    "#df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000010\n"
     ]
    }
   ],
   "source": [
    "i = 0;\n",
    "for chunk in pd.read_csv('bookings.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000):\n",
    "    i = i + len(chunk.index)\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20390198\n"
     ]
    }
   ],
   "source": [
    "i = 0;\n",
    "for chunk in pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000):\n",
    "    i = i + len(chunk.index)\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "with bz2.BZ2File('searches.csv.bz2') as fileBz2:\n",
    "    k = 0\n",
    "    for line in fileBz2:\n",
    "        k+=1\n",
    "\n",
    "print(k);\n",
    "\n",
    "fileBz2.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import \n",
    ">>> df = pd.DataFrame.from_dict({'A': {1: datetime.datetime.now()}})\n",
    ">>> df\n",
    "\n",
    "for chunk in pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000):\n",
    "    records = json.loads(df.T.to_json()).values()\n",
    "    db.myCollection.insert(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.groupby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "     arr_port    pax\n",
      "1088      LHR  88809\n",
      "1190      MCO  70930\n",
      "1050      LAX  70530\n",
      "1047      LAS  69630\n",
      "886       JFK  66270\n",
      "315       CDG  64490\n",
      "216       BKK  59460\n",
      "1228      MIA  58150\n",
      "1719      SFO  58000\n",
      "517       DXB  55590\n"
     ]
    }
   ],
   "source": [
    "#2   MIRAR DUPLICADOS -> FALTA\n",
    "col_list = ['arr_port','pax']\n",
    "dfaux = pd.DataFrame(columns = col_list)\n",
    "\n",
    "\n",
    "for chunk in pd.read_csv('bookings.csv.bz2', compression='bz2', header=0, sep='^', chunksize=50000, usecols=col_list):        \n",
    "    chunk['arr_port'] = chunk['arr_port'].str.strip()\n",
    "    chunk['arr_port'] = chunk['arr_port'].str.upper()\n",
    "    chunk.dropna()\n",
    "    #chunk.duplicated().unique()\n",
    "    dfaux2 = chunk[['arr_port','pax']]\n",
    "    dfaux = dfaux.append(dfaux2,ignore_index=True)\n",
    "    \n",
    "#df['DataFrame Column'] = df['DataFrame Column'].astype(int)\n",
    "\n",
    "salida = dfaux.groupby(['arr_port'])['pax'].sum().reset_index().sort_values(by=['pax'], ascending=False).head(10)\n",
    "\n",
    "salida = salida.astype({\"pax\": int})\n",
    "\n",
    "print(salida)\n",
    "\n",
    "salida.to_csv('resultado_ejercicio_2_grupo_1.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.append?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.dropna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_searches['dest_MAD_BCN_AGP'] = np.where(df_searches['Destination'] == city_dest_1, city_dest_1, df_searches['dest_MAD_BCN_AGP'])\n",
    "\n",
    "df_searches['dest_MAD_BCN_AGP'] = np.where(df_searches['Destination'] == city_dest_2, city_dest_2, df_searches['dest_MAD_BCN_AGP'])\n",
    "\n",
    "df_searches['dest_MAD_BCN_AGP'] = np.where(df_searches['Destination'] == city_dest_3, city_dest_3, df_searches['dest_MAD_BCN_AGP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ac5778e6989e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdateparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'searches.csv.bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'^'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdateparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')\n",
    "\n",
    "for chunk in pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000, parse_dates=['Date'], date_parser=dateparse): \n",
    "    break;\n",
    "\n",
    "chunk.index = pd.to_datetime(chunk['Date'], format='%Y-%m-%d')\n",
    "#groupby(by=[chunk.index.month, chunk.index.year])\n",
    "chunk_filter = chunk[chunk['Destination'].isin(['MAD', 'BCN','AGP'])]\n",
    "\n",
    "chunk_filter_MAD = chunk[chunk['Destination'].isin(['MAD'])]\n",
    "chunk_filter_BCN = chunk[chunk['Destination'].isin(['BCN'])]\n",
    "chunk_filter_AGP = chunk[chunk['Destination'].isin(['AGP'])]\n",
    "\n",
    "chunk_filter_MAD.groupby(by=[chunk_filter.index.month, chunk_filter.index.year])\n",
    "#chunk_filter_BCN.groupby(by=[chunk_filter.index.month, chunk_filter.index.year])\n",
    "#chunk_filter_AGP.groupby(by=[chunk_filter.index.month, chunk_filter.index.year])\n",
    "\n",
    "'''\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "sns.pointplot(data=searches_sample2,\n",
    "\n",
    "       x=[chunk.index.month, chunk.index.year],\n",
    "\n",
    "       y='size',\n",
    "\n",
    "       estimator=np.mean,\n",
    "\n",
    "       ax=ax,\n",
    "\n",
    "       hue='Destination',\n",
    "\n",
    "       ci='sd',\n",
    "\n",
    "       #order= agesOrder\n",
    ");\n",
    "'''\n",
    "\n",
    "#chunk_filter['Destination'].groupby(by=[chunk_filter.index.month, chunk_filter.index.year]).head(10)\n",
    "#chunk.columns.tolist()\n",
    "#chunk[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear dataframe auxiliar\n",
    "# recorrer dataframe original para obtener cabeceras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for chunk in pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^', chunksize=5):\n",
    "    col_list = list(chunck.columns.values)\n",
    "    break;\n",
    "\n",
    "dfaux = pd.DataFrame(columns = col_list)\n",
    "\n",
    "\n",
    "for chunk in pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^', chunksize=1000):\n",
    "    dfaux = list(chunck.columns.values)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0;\n",
    "for chunk in pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000):\n",
    "    i = i + len(chunk.index)\n",
    "    \n",
    "print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
