{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookings.csv  bookings.csv.bz2\tchallenge.ipynb  searches.csv  searches.csv.bz2\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000011\r\n"
     ]
    }
   ],
   "source": [
    "!cat bookings.csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20390198\r\n"
     ]
    }
   ],
   "source": [
    "!cat searches.csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-10-13^12:34:56^MPT^90e8ff571fc484463158eae496711466^SE^GOT^NBO^1^2^GOT^NBO^2013-12-05^^^NBO^GOT^2014-02-28^^^^^^^^^^^^^^^^^^^^^^^1ASIWS^0^0^0^d41d8cd98f00b204e9800998ecf8427e^0\r\n",
      "2013-10-13^10:03:58^FXP^9530f0a7e694bc9402885b4fa7e094bd^TR^DUS^ALA^1^4^DUS^IST^2013-12-16^EU^L^IST^ALA^2013-12-16^EU^L^ALA^IST^2013-12-24^EU^E^IST^DUS^2013-12-25^EU^E^^^^^^^^^^^1ASI^0^0^0^d41d8cd98f00b204e9800998ecf8427e^0\r\n",
      "2013-10-13^14:11:34^FXP^594fed8de13248512f6cf4cf9f6fc915^KW^KWI^LHR^1^2^KWI^LHR^2013-11-26^LK^F^LHR^KWI^2013-12-06^LK^F^^^^^^^^^^^^^^^^^^^^^1ASI^0^0^0^d41d8cd98f00b204e9800998ecf8427e^0\r\n",
      "2013-10-13^05:47:30^MPT^e175ff926640d0f543bb15f8b4a88ed0^US^MFE^MAD^0^1^MFE^MAD^2014-05-30^LK^^^^^^^^^^^^^^^^^^^^^^^^^^^1ASI^0^0^0^d41d8cd98f00b204e9800998ecf8427e^0\r\n",
      "2013-10-13^18:57:54^MTP^e41c9d833aa74600552f2ed688b67d81^AT^VIE^HA"
     ]
    }
   ],
   "source": [
    "!tail -5 searches.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-05-18 00:00:00^1A    ^LK      ^1a5585bef21f0bf8dc865a87843635f9^6ff8fd087f94799d7aed903683384775^3b339797f7eca14c24e8b7565da822c0^2013-05-14 00:00:00^13203^0^CMB     ^CMB     ^LK      ^MAA     ^MAA     ^IN      ^CMB     ^CMB     ^LK      ^MAA     ^MAA     ^IN      ^CMB     ^CMB     ^LK      ^CMBMAA  ^CMBMAA  ^INLK    ^1^MAACMB         ^FV^V        ^Y        ^2013-05-24 16:05:00^2013-05-24 17:38:39^-1^2013^5^NULL     \r\n",
      "2013-05-18 00:00:00^1A    ^LK      ^1a5585bef21f0bf8dc865a87843635f9^6ff8fd087f94799d7aed903683384775^3b339797f7eca14c24e8b7565da822c0^2013-05-14 00:00:00^6003^0^CMB     ^CMB     ^LK      ^MAA     ^MAA     ^IN      ^CMB     ^CMB     ^LK      ^MAA     ^MAA     ^IN      ^CMB     ^CMB     ^LK      ^CMBMAA  ^CMBMAA  ^INLK    ^1^MAACMB         ^FV^V        ^Y        ^2013-05-19 16:05:00^2013-05-19 17:38:39^1^2013^5^NULL     \r\n",
      "2013-05-28 00:00:00^1A    ^US      ^07e98d2fd3cd4b737266b99727f7faa8^e8741eaf2fa2f71f931475d18fa72096^2b22597bdad931843c3b1d5219836e07^2013-05-28 00:00:00^328^1865^AUS     ^AUS     ^US      ^RDU     ^RDU     ^US      ^RDU     ^RDU     ^US      ^AUS     ^AUS     ^US      ^RDU     ^RDU     ^US      ^AUSRDU  ^AUSRDU  ^USUS    ^0^AUSDFWRDU      ^KK^Q        ^Y        ^2013-07-12 08:35:00^2013-07-12 15:03:14^1^2013^5^SEAEX38AA\r\n",
      "2013-05-28 00:00:00^1A    ^FR      ^e2679367673d50f1ee085127d8a00eba^5f26f53ca29672815e0ee3bd93a2b0e4^4eb40315a7263131ae17712cd505b62a^2013-05-28 00:00:00^588^0^TLS     ^TLS     ^FR      ^ORY     ^PAR     ^FR      ^TLS     ^TLS     ^FR      ^TLS     ^TLS     ^FR      ^ORY     ^PAR     ^FR      ^ORYTLS  ^PARTLS  ^FRFR    ^0^TLSORY         ^KP^S        ^Y        ^2013-06-04 10:50:00^2013-06-04 12:18:20^1^2013^5^LYSSR210Z\r\n",
      "2013-05-28 00:00:00^1A    ^FR      ^e2679367673d50f1ee085127d8a00eba^5f26f53ca29672815e0ee3bd93a2b0e4^4eb40315a7263131ae17712cd505b62a^2013-05-28 00:00:00^588^0^TLS     ^TLS     ^FR      ^ORY     ^PAR     ^FR      ^TLS     ^TLS     ^FR      ^ORY     ^PAR     ^FR      ^TLS     ^TLS     ^FR      ^ORYTLS  ^PARTLS  ^FRFR    ^0^ORYTLS         ^KP^S        ^Y        ^2013-06-04 19:10:00^2013-06-04 20:38:20^1^2013^5^LYSSR210Z\r\n"
     ]
    }
   ],
   "source": [
    "!tail -5 bookings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('bookings.csv', index_col=0)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('searches.csv', index_col=0)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv('bookings.csv.bz2', compression='bz2', header=0, sep='^')\n",
    "#df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000010\n"
     ]
    }
   ],
   "source": [
    "i = 0;\n",
    "for chunk in pd.read_csv('bookings.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000):\n",
    "    i = i + len(chunk.index)\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20390198\n"
     ]
    }
   ],
   "source": [
    "i = 0;\n",
    "for chunk in pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000):\n",
    "    i = i + len(chunk.index)\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "with bz2.BZ2File('searches.csv.bz2') as fileBz2:\n",
    "    k = 0\n",
    "    for line in fileBz2:\n",
    "        k+=1\n",
    "\n",
    "print(k);\n",
    "\n",
    "fileBz2.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import \n",
    ">>> df = pd.DataFrame.from_dict({'A': {1: datetime.datetime.now()}})\n",
    ">>> df\n",
    "\n",
    "for chunk in pd.read_csv('searches.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000):\n",
    "    records = json.loads(df.T.to_json()).values()\n",
    "    db.myCollection.insert(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['arr_port','pax']\n",
    "\n",
    "for chunk in pd.read_csv('bookings.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000, usecols=col_list):        \n",
    "    break;\n",
    "    \n",
    "#for chunk in pd.read_csv('bookings.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000, names=heads):\n",
    "\n",
    "    #break;\n",
    "    \n",
    "# pd.read_csv(\"path/to/file.txt\", sep='\\t', names=[\"Sequence\", \"Start\", \"End\", \"Coverage\"])\n",
    "chunk['arr_port'] = chunk['arr_port'].str.strip()\n",
    "chunk['arr_port'] = chunk['arr_port'].str.upper()\n",
    "\n",
    "#chunk['pax'] = chunk['pax'].str.strip()\n",
    "\n",
    "chunk.dropna();\n",
    "\n",
    "chunk.groupby(['arr_port'])['pax'].sum().reset_index()\n",
    "\n",
    "#chunk['arr_port'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.groupby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_port</th>\n",
       "      <th>pax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>LHR</td>\n",
       "      <td>88809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>MCO</td>\n",
       "      <td>70930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>LAX</td>\n",
       "      <td>70530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>LAS</td>\n",
       "      <td>69630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>JFK</td>\n",
       "      <td>66270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>CDG</td>\n",
       "      <td>64490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>BKK</td>\n",
       "      <td>59460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>MIA</td>\n",
       "      <td>58150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>SFO</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>DXB</td>\n",
       "      <td>55590.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_port      pax\n",
       "1088      LHR  88809.0\n",
       "1190      MCO  70930.0\n",
       "1050      LAX  70530.0\n",
       "1047      LAS  69630.0\n",
       "886       JFK  66270.0\n",
       "315       CDG  64490.0\n",
       "216       BKK  59460.0\n",
       "1228      MIA  58150.0\n",
       "1719      SFO  58000.0\n",
       "517       DXB  55590.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = ['arr_port','pax']\n",
    "dfaux = pd.DataFrame(columns = col_list)\n",
    "\n",
    "for chunk in pd.read_csv('bookings.csv.bz2', compression='bz2', header=0, sep='^', chunksize=10000, usecols=col_list):        \n",
    "    chunk['arr_port'] = chunk['arr_port'].str.strip()\n",
    "    chunk['arr_port'] = chunk['arr_port'].str.upper()\n",
    "    chunk.dropna()\n",
    "    dfaux2 = chunk.groupby(['arr_port'])['pax'].sum().reset_index()\n",
    "    dfaux = dfaux.append(dfaux2,ignore_index=True)\n",
    "    \n",
    "#df['DataFrame Column'] = df['DataFrame Column'].astype(int)\n",
    "\n",
    "dfaux.groupby(['arr_port'])['pax'].sum().reset_index().sort_values(by=['pax'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.append?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.dropna?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
